{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Data Analysis with Pandas & Jupyter, November 2019\n",
    "\n",
    "Workshop lead: Sam Bail [@spbail](http://twitter.com/spbail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "The goal of this workshop is to give learners an intro to data analysis with Python using Pandas and Jupyter. \n",
    "We will first go through the process of loading data from CSV files, inspecting and cleaning the data. As a second step, we will analyse the data and draw some insights about cancer treatment from it. \n",
    "\n",
    "The tutorial is structured as follows:\n",
    "\n",
    "- Intro and background\n",
    "- Part 0: Quick Jupyter exercise\n",
    "- Part 1: Loading and inspecting data\n",
    "- Part 2: Data cleaning\n",
    "- Part 3: Data analysis\n",
    "- Part 4: Summary\n",
    "\n",
    "**Note that this tutorial is only intended as an introduction to some basic concepts of Pandas. It is in no means intended to be comprehensive, and there are a lot of useful functions a beginner needs to know to do in-depth data analysis. We hope that this tutorial sets you up for self-guided learning to master the full range of necessary Pandas tools.**\n",
    "\n",
    "## How to follow along with the workshop\n",
    "- You can run every cell in the notebook as we go along using the shortcut Shift+Enter\n",
    "- You will encounter a few <span style=\"color:blue\">*** DIY exercise ***</span> blocks where you'll get a few minutes to try out what you've just learned\n",
    "- Feel free to save and download your notebook from Binder at the end since Binder deletes notebooks after 12 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "## What is Jupyter (and the Jupyter ecosystem...)?\n",
    "- **IPython** is an **interactive Python shell** (just type \"ipython\" to start it)\n",
    "- **Jupyter** is a Python library that provides a **web-based UI** on top of ipython to create notebooks with code and output\n",
    "- **JupyterLab** provides some additional **features on top of Jupyter**, e.g. a file browser\n",
    "- **Binder** is a **web-based hub** for containers that contain your Python environment and renders notebooks based on a git repo\n",
    "\n",
    "## What is Pandas/Matplotlib/Pyplot/Seaborn?\n",
    "\n",
    "- **Pandas** is a Python library for **data manipulation and analysis**. It offers data structures and operations for manipulating numerical tables and time series.\n",
    "- **Matplotlib** is a Python **2D plotting library**. Pyplot is a collection of command style functions in matplotlib that make matplotlib work like MATLAB. While we mostly use Seaborn, we sometimes fall back to using Pyplot functions for certain aspects of plotting.\n",
    "- **Seaborn** is a Python **data visualization** library based on matplotlib. It's kind of like a nicer version of Pyplot.\n",
    "- You can **use Pandas code in a regular Python script** of course. I'm just combining Jupyter + Pandas in this tutorial because notebooks are a great way to immediately see output!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Quick Jupyter exercise (10 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebooks are basically just interactive ipython terminals, often mixed in with markdown text:\n",
    "- Each input field you see is called a **cell**\n",
    "- Cells can be **either code or markdown**\n",
    "- You can execute any kind of Python code\n",
    "- **Variables persist** between cells\n",
    "- The notebook **doesn't care about the order of cells**, just the order of executing it in order to remember variables. However, \"run all\" executes your cells top to bottom.\n",
    "\n",
    "### Notebooks have **two modes**: a) editing the cells and b) navigating the notebook (command mode):\n",
    "- You can **navigate** around the notebook in command mode by clicking cells or using the arrow keys\n",
    "- Depending on the environment you're using (Jupyter notebook, Jupyter lab, Google Colab...) there will be a different **visual cue** (e.g. a colored line) to indicate the mode a cell is in\n",
    "- In order to **edit a cell**, you can press **Enter** or double-click it.\n",
    "- To **execute** the cell content, press Shift+Enter to run the cell\n",
    "- To get **out of edit mode** and back into navigation mode, press the **Escape key**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some helpful keyboard shortcuts:\n",
    "- The **default type for a cell is code**. In command mode, press *m* to make a cell markdown and *y* to make it code\n",
    "- Press *a* in command mode to create a new cell *above* the current one\n",
    "- Press *b* in command mode to create a new cell *below* the current one\n",
    "- *Tab* autocompletes methods (like in IPython)\n",
    "- *Shift+Tab* shows you the docstring for the outer function of the line your cursor is in\n",
    "- Press *dd* in command mode to delete a cell. \n",
    "- *Cmd+z* undoes operations in the highlighted cell, *z* undoes cell operations in the notebook (e.g. deleting a cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples\n",
    "\n",
    "print('Hello world!')\n",
    "\n",
    "import math\n",
    "math.ceil(4.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell magic in Jupyter\n",
    "A \"cell magic\" is a wrapper function that applies to a line or entire cell in a notebook. Jupyter comes with several built-in \"magic\" functions.\n",
    "- A single % before the name indicates a line-specific function\n",
    "- A double %% applies the function to the entire cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line-specific magic to time the statement execution\n",
    "import numpy\n",
    "%time numpy.random.normal(size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# The magic applies to the whole cell and must come first!\n",
    "numpy.random.normal(size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*** DIY exercise ***</span>\n",
    "Try out using only your keyboard and shortcuts for these two tasks:\n",
    "- Create a new *markdown* cell below this one, write a few lines and format them to look like a header and bullets.\n",
    "- Create a new *code* cell above the first one one, import your favorite Python function, check out the docstring, and execute the code (e.g. `os.getcwd()`, `random.random()`, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Loading and inspecting the data (20 mins)\n",
    "\n",
    "Before we can start answering questions about the data we need to do a little bit of exploratory analysis.The first thing we need to do when working with a new dataset is to get an idea of what the data looks like. We start by loading the data into memory. Pandas comes with a built-in `read_csv` function that we can use to read CSV files and load them directly to a pandas `DataFrame` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to import the libraries to start with\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# This command makes charts show inline in a notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Making the figures show up a little larger than default size\n",
    "plt.rcParams['figure.figsize'] = [10,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a dataframe?\n",
    "* A **dataframe** is a **2-dimensional labeled data structure** with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects. It is generally the most commonly used Pandas object. \n",
    "* Pandas borrows the concept of DataFrame from the statistical programming language R.\n",
    "* There are a lot of **different ways to read data** into a dataframe - from lists, dicts, CSVs, databases... In this example, we're loading data from a CSV file!\n",
    "\n",
    "**Let's take a look at the data to familiarize ourselves with the format and data types. In this example, I'm using some treatment data from the oncology domain, including treatment starts and the drugs patients are getting.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from a CSV into a dataframe\n",
    "# This is the data we're going to be working with!\n",
    "tx = pd.read_csv('./mock_treatment_starts_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just typing the name of the dataframe will print the entire output\n",
    "# If there are too many rows, Jupyter will print the top few and \n",
    "# bottom few rows with a \"...\" to indicate that there are more rows\n",
    "tx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting a dataframe using built-in functions\n",
    "* Most operations on a dataframe happen by applying a function to it using the \".\" notation, e.g. `my_dataframe.do_something()`\n",
    "* Let's look at some simple functions that we can apply to Pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The info() function prints some basic information about the dataframe\n",
    "# such as the number of columns and rows\n",
    "# Let's talk about the # column later!\n",
    "tx.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The head(n) function shows the first n rows in a dataframe.\n",
    "# If no n is specified, it defaults to 5 rows.\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use the sample() function to get n random rows in \n",
    "# the dataframe\n",
    "tx.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The describe function shows some basic statistics for numeric columns\n",
    "# We only have one here (Dosage), so this isn't very interesting\n",
    "tx.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other ways to inspect a dataframe\n",
    "* There are other operations you can do on a dataframe that don't follow the function notation\n",
    "* Let's look at a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then len function gives us the number of rows in the dataframe\n",
    "len(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The shape property gives you the number of rows and columns\n",
    "tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dtypes property of a dataframe shows the datatypes of \n",
    "# every column in a dataframe.\n",
    "tx.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns attribute of a dataframe contains the column names\n",
    "# We'll talk about the \"Index\" later!\n",
    "tx.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*** DIY exercise ***</span>\n",
    "Create a new cell below and print the first ten rows of the \"tx\" dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing columns in a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Note: We will be applying `head()` to some results in this tutorial to keep the output short. When working with a real dataset, keep in mind that you might be hiding some relevant records if you always use `head()` or `sample()`!**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's assume you just want to print a specific column or row from your dataframe.** \n",
    "\n",
    "In Pandas, you can access a specific column using the following notation which returns a **Series** (not a dataframe).\n",
    "\n",
    "A series is simply a **vector**, aka a 1-dimensional data structure similar to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the PatientID column as a Series\n",
    "tx['PatientID'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type to show that this indeed returns a Series object\n",
    "type(tx['PatientID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The alternative notation for accessing a column in a dataframe\n",
    "# Some people prefer the . notation, others the [] notation.\n",
    "# Personally, I prefer using [] for visibility and consistency\n",
    "tx.PatientID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And this is how you access two columns of a dataframe.\n",
    "# Note that this will return a dataframe again, not a series \n",
    "# (because a series has only one column...)\n",
    "# Also note the double square brackets \n",
    "# because you're passing a *list* of columns as an argument\n",
    "tx[['PatientID', 'Dosage']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type to confirm that this returns a DataFrame type\n",
    "type(tx[['PatientID', 'TreatmentStart']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This way we can now do some more data exploration, \n",
    "# e.g. looking at unique patient IDs using the unique function\n",
    "# which returns an array of values\n",
    "tx['PatientID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*** DIY exercise ***</span>\n",
    "Create a new cell below and print the list of unique drugs in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing rows in a dataframe\n",
    "In addition to slicing by column, we often want to get the record where a column has a specific value, e.g. a specific Patient_ID here. This can be done using the `.loc` function syntax and a boolean statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the record(s) where the value in the PatientID column is PT20\n",
    "tx.loc[tx['PatientID'] == 'PT20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is equivalent to the following shorter notation\n",
    "# I prefer to always use loc to be more explicit\n",
    "tx[tx['PatientID'] == 'PT20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use boolean conditions in the selector\n",
    "tx.loc[(tx['PatientID'] == 'PT20') & (tx['Drug'] == 'Cisplatin')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*** DIY exercise ***</span>\n",
    "Create a new cell below and show all rows where the drug dosage for Cisplatin is less than 180."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting dataframes\n",
    "Sorting the output of a dataframe can be helpful for visually inspecting or presenting data! Sorting by one or multiple columns is super easy using the `sort_values` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by earliest treatment start date, i.e. in ascending order (default)\n",
    "tx.sort_values('TreatmentStart').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by latest treatment start, i.e. in descending order\n",
    "tx.sort_values('TreatmentStart', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, you can also sort by a list of columns. If you want to \n",
    "# change the ascending/descending orders, pass a **list** of \n",
    "# booleans to the `ascending` parameter!\n",
    "tx.sort_values(['PatientID', 'TreatmentStart']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `inplace` parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Any operations on a dataframe are *not* permanent, i.e. they only modify the current output, but not the actual dataframe. If you want to preserve the sorting, for example, you have to either assign the output to a new variable, or use the `inplace=True` argument. This will not create any output but actually modify the dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the dataframe\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the inplace keyword to modify the dataframe\n",
    "# Note that you can also sort by a list of columns\n",
    "tx.sort_values(['PatientID', 'TreatmentStart'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the permanently sorted dataframe\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*** DIY exercise ***</span>\n",
    "Create a new cell below and sort the dataframe by drug (ascending, i.e. alphabetically) and then dosage (descending order, i.e. highest dosage first)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Data cleaning (15 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember the dtypes property?\n",
    "# The TreatmentStart column should really be a date, right?\n",
    "tx.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right away we can see that the date field TreatmentDate is stored as string (object). It might be useful to convert it to **Datetime** objects so that we can perform common date arithmetic on them, like checking if a date came before or after another date, or calculating the number of days between two dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assigns the datetime version of the TreatmentStart column \n",
    "# to a column with the same name\n",
    "tx['TreatmentStart'] = pd.to_datetime(tx['TreatmentStart'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the types now - we have a datetime64 type!\n",
    "tx.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the alternative notation to access a column in a dataframe\n",
    "tx.TreatmentStart = pd.to_datetime(tx.TreatmentStart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidebar: Copying dataframes and dropping columns\n",
    "Sometimes you might want to copy a dataframe, e.g. to do further transformations on it but keep the original.\n",
    "\n",
    "**Note** that if you assign a dataframe to a new variable, it will reference the same underlying object as the original dataframe. This means that any modification you make to the new dataframe will also be applied to the old one. Use the `copy()` function to make a new copy of the dataframe by value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txcopy = tx\n",
    "\n",
    "# Create a new dummy column in the \"copy\" of our dataframe\n",
    "txcopy['NewColumn'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txcopy now has the new column...\n",
    "txcopy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... but so does our original dataframe. This is not really what we want!\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the dummy column from the original dataframe\n",
    "# axis=1 means we're dropping columns, and we need to \n",
    "# use inplace=True to make it permanent!\n",
    "if 'NewColumn' in tx.columns:\n",
    "    tx.drop('NewColumn', axis=1, inplace=True)\n",
    "\n",
    "# Then make a *real* copy of the \"clean\" tx dataframe\n",
    "txcopy = tx.copy()\n",
    "\n",
    "# Add the dummy column to tx2 and confirm that the \n",
    "# original tx doesn't have it\n",
    "txcopy['NewColumn'] = 1\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and confirm that the second dataframe does have the column:\n",
    "tx2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*** DIY exercise ***</span>\n",
    "Create a copy of the tx dataframe called `mytx` and add a new column called  `TreatmentStartDT` that contains the treatment starts as datetime types.\n",
    "\n",
    "Then print the head() of `mytx.dtypes` to show the datatypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Data analysis (30 minutes)\n",
    "Let's assume we've loaded the treatment related data from a cancer clinic in order to provide them with some analytical insights around the types of drugs they use on their patient population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Patients treated at the practice\n",
    "\n",
    "**How many unique patients does the practice treat?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data frame contains patient IDs and treatment starts -\n",
    "# let's check if some patients have multiple treatment starts?\n",
    "# The unique() function returns the number of unique values \n",
    "# in a dataframe column.\n",
    "print('Number of treatment start records:', len(tx))\n",
    "print('Number of unique patients who start treatment:', \n",
    "      len(tx.PatientID.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 20 unique patients but we have 24 treatment start records, meaning some patients start multiple treatments in the time that we have data for. This means that if we want to answer the question correctly, we need to make sure to only count unique patients. Let's learn some counting techniques first before coming back to the duplicate issue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Drugs used at the practice\n",
    "**What are the drugs used at the practice and how many patients receive those drugs?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx.groupby('Drug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The groupby function works like a groupby in SQL, i.e. it \n",
    "# groups the dataframe by the specified column and then lets you \n",
    "# apply aggregate functions on the grouped values, \n",
    "# e.g. counts, sums, means...\n",
    "# The count function counts the number of rows with *non-null values* \n",
    "# in a column\n",
    "tx.groupby('Drug').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are only interested in the number of patients, \n",
    "# we can select only the relevant column from the resulting \n",
    "# dataframe in the output table\n",
    "\n",
    "# Note that \"PatientID\" might not be the best name for this column\n",
    "# - we can use a rename() function in Pandas to rename it to something \n",
    "# like \"PatientCount\" \n",
    "# I'm skipping renaming in this tutorial, but feel free to look it up!\n",
    "tx.groupby('Drug').count()[['PatientID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use nunique() which counts the number of *unique* non-null values for each column\n",
    "# Notice how the numbers are different from the count() result in the TreatmentStart and Dosage columns\n",
    "tx.groupby('Drug').nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*** DIY exercise ***</span>\n",
    "With the techniques you just learned in Question 2, think back to Question 1. Create a new cell below and count how many records each patient has in order to spot those patients that receive more than one treatment.\n",
    "\n",
    "**Additional point to think about:** Depending on what question we want to answer, counting the number of records might not give us the correct answer. Can you think of different questions a clinic might ask to explain why patients have multiple records? What stands out when using nunique() instead of count()?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little bit about indexes in dataframes\n",
    "Notice that in the above example, the \"Drug\" column is printed in bold. That's because grouping by it has turned it into the **index** of the resulting dataframe.\n",
    "\n",
    "The index in a dataframe is the **\"row identifier\"** - it is generally printed as the column on the left. For example, when we first loaded our data, the index didn't have a name and was just an incrementing integer (scroll up to check!). When you create a groupby object, the index of a resulting dataframe will be the column you group by - in this case, the Drug column became the index.\n",
    "\n",
    "We frequently **reset** the index in a dataframe for various reasons - in this case, because the index contains data that you want to treat as a column, e.g. for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same groupby we did above. Notice how the \"Drug\" column is bold\n",
    "# - it became the index after grouping by it\n",
    "tx.groupby('Drug').count()[['PatientID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index in the grouped dataframe to see what happens:\n",
    "tx.groupby('Drug').count()[['PatientID']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that any operations on the dataframe only modify the output? \n",
    "# We didn't *really* group the dataframe or reset the index. \n",
    "# The tx dataframe is still the same it was at the beginning.\n",
    "# We could use inplace=True to make the change permanent.\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's plot this! (aka our first Seaborn plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do the same groupby as above to get the number of patient starts per drug.\n",
    "# This time, we actually assign the output to a new dataframe `counts` to \n",
    "# make the change permanent.\n",
    "counts = tx.groupby('Drug').count()[['PatientID']].reset_index()\n",
    "\n",
    "# Let's use a simple bar chart in Seaborn to compare counts for the two drugs\n",
    "# There are several different ways to do the plotting - this is my preferred style,\n",
    "# but you might prefer different syntax\n",
    "fig = sns.barplot(data=counts, x='Drug', y='PatientID')\n",
    "plt.title('Number of patient starts by drug')\n",
    "plt.ylabel('Number of patient starts')\n",
    "plt.xlabel('Drug')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Changes to treatment over time\n",
    "**Do we see any changes in treatment patterns over time?**\n",
    "\n",
    "Our data shows treatment starts by date. Let's group these starts by month to see if there are any changes of how many patients start on a given drug over time, e.g. because a new drug got approved.\n",
    "\n",
    "*Note that the data we're using here is dummy data and pretty artificial - oncology clinics see a much higher volume of patients, and drug uptake is usually slower than shown here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add a new column that only has the treatment *month* to simplify things\n",
    "# There are many different ways to do this, we picked a simple one called \"astype\"\n",
    "tx['TreatmentStartMonth'] = tx['TreatmentStart'].astype('datetime64[M]')\n",
    "\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's count the number of starts per month per drug to plot it later\n",
    "# We only want the number of patients, so we filter for that column at the end\n",
    "drugs_by_month = tx.groupby(['TreatmentStartMonth', 'Drug']).count()[['PatientID']]\n",
    "drugs_by_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data already looks interesting... let's plot this \n",
    "# Remember to reset_index so we can plot the regular columns\n",
    "# The \"hue\" keyword is generally used to distinguish two different \n",
    "# categorical variables in plots, e.g. in this case the two different drugs\n",
    "# NOTE: lineplot() only exists in Seaborn version 0.9 and up\n",
    "fig = sns.lineplot(data=drugs_by_month.reset_index(), \n",
    "                   x='TreatmentStartMonth', \n",
    "                   y='PatientID',\n",
    "                   hue='Drug')\n",
    "plt.title('Number of patient starts by drug and by month')\n",
    "plt.ylabel('Number of patient starts')\n",
    "plt.xlabel('Drug')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*** DIY exercise ***</span>\n",
    "Plot `drugs_by_month` as a clustered barplot instead of lineplot. Make sure you're clear about what your x, y, and hue are in this case!\n",
    "\n",
    "Note that the date labeling on the x axis doesn't look good because Seaborn converts the month back to a datetime. There are several ways to deal with this - can you think of one possible solution that works in this particular case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] Question 4: Dosage and outliers\n",
    "**Question: What is the average dosage of each drug? Are there any outliers?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An easy first step is to group by the respective drug and use describe()\n",
    "tx.groupby(['Drug']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of a more complex way to get aggregates in Pandas\n",
    "# The agg function takes a dictionary of column:function pairs,\n",
    "# where \"function\" can be a built-in function like count, mean, min, etc, \n",
    "# or a custom function like a lambda.\n",
    "tx.groupby(['Drug']).agg({'Dosage': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also pass a list of functions to a column to get multiple outputs!\n",
    "tx.groupby(['Drug']).agg({'Dosage': ['count', 'mean', 'std', 'min', 'max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot this easily in Seaborn - but the outlier squashes our display\n",
    "fig = sns.boxplot(data=tx, x='Drug', y='Dosage')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use showfliers=False in a boxplot to suppress outliers\n",
    "fig = sns.boxplot(data=tx, x='Drug', y='Dosage', showfliers=False)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Summary!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hope this workshop was useful for you. We've only touched on some of the **basic concepts** of Pandas, but we believe this will give you the foundations to keep exploring the data! We covered:\n",
    "\n",
    "- Basic operations in Jupyter notebooks\n",
    "- Dataframes and Series in Pandas, and loading data to a dataframe\n",
    "- Basic data inspection (head, describe, dtypes, accessing columns and rows, sorting)\n",
    "- Grouping and aggregating (count, nunique)\n",
    "- Indexing in dataframes and reset_index\n",
    "- Plotting (bar plots, line plots)\n",
    "\n",
    "**What we didn't learn:**\n",
    "\n",
    "This is my (biased) list of very frequent Pandas operations that we didn't cover but you'll likely need for data analysis:\n",
    "- Joining/merging multiple dataframes\n",
    "- Filtering and de-duplicating dataframes\n",
    "- More complex modifications of column values, e.g. filling null values, using lambda functions\n",
    "- More complex aggregates on grouped dataframes (sum, mean, etc)\n",
    "- Renaming columns (e.g. renaming an aggregate \"PatientID\" column to something more meaningful like \"PatientCount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me know what you think! samanthapbail@gmail.com / [@spbail](http://twitter.com/spbail)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
